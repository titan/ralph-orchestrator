# TUI Integration Test Plan with Real Claude Invocations and Insta Snapshots

## Context

The TUI has been refactored from a VT100 terminal emulator to an observation dashboard. We need comprehensive integration tests that:

1. Verify TUI state transitions using deterministic replay
2. Validate real-world behavior with actual Claude invocations
3. Catch visual regressions before they reach users

## Goals

- **Fast feedback**: Deterministic tests that run in CI under 10 seconds
- **Behavioral confidence**: Real Claude E2E tests that catch integration bugs
- **Visual validation**: LLM-as-judge for subjective UI criteria

## Architecture

```
┌─────────────────────────────────────────────────────────────────────────┐
│                       Test Pyramid for TUI                              │
├─────────────────────────────────────────────────────────────────────────┤
│                                                                         │
│  ▲ Slow, Real Claude                                                    │
│  │  ┌─────────────────────────────────────────────────────────────┐    │
│  │  │  Python E2E Tests (tools/e2e/)                              │    │
│  │  │  - Real Claude invocations via tmux                         │    │
│  │  │  - LLM-as-judge for semantic validation                     │    │
│  │  │  - Captures SVG screenshots as evidence                     │    │
│  │  └─────────────────────────────────────────────────────────────┘    │
│  │                                                                      │
│  │  ┌─────────────────────────────────────────────────────────────┐    │
│  │  │  Rust Integration Tests (insta + JSONL replay)              │    │
│  │  │  - ReplayBackend drives TUI with recorded sessions          │    │
│  │  │  - insta snapshots for state transitions                    │    │
│  │  │  - Deterministic, fast, no API calls                        │    │
│  │  └─────────────────────────────────────────────────────────────┘    │
│  │                                                                      │
│  │  ┌─────────────────────────────────────────────────────────────┐    │
│  ▼  │  Unit Tests (existing 350+ tests)                           │    │
│ Fast│  - Widget rendering, state transitions, input handling      │    │
│     └─────────────────────────────────────────────────────────────┘    │
│                                                                         │
└─────────────────────────────────────────────────────────────────────────┘
```

---

## Tier 1: Rust Insta Integration Tests (Deterministic)

### Dependencies

Add to `crates/ralph-tui/Cargo.toml`:

```toml
[dev-dependencies]
insta = { version = "1.40", features = ["yaml", "redactions"] }
ralph-core = { workspace = true, features = ["testing"] }
```

### Fixture Directory Structure

```
crates/ralph-tui/tests/
├── common/
│   └── mod.rs                          # TuiTestHarness
├── fixtures/
│   ├── multi_iteration_session.jsonl   # 3 iterations with events
│   ├── hat_transitions.jsonl           # task.start → build.task → build.done
│   ├── search_scenario.jsonl           # Content with searchable terms
│   ├── long_output_scroll.jsonl        # 500+ lines for scroll testing
│   └── completion_session.jsonl        # LOOP_COMPLETE termination
├── snapshots/                          # Auto-generated by insta
│   └── *.snap
└── integration_snapshots.rs            # Snapshot tests
```

### Test Harness Implementation

Create `crates/ralph-tui/tests/common/mod.rs`:

```rust
use ralph_core::testing::ReplayBackend;
use ralph_tui::{TuiState, Action};
use ratatui::backend::TestBackend;
use ratatui::Terminal;
use std::sync::{Arc, Mutex};

/// Test harness that drives TUI with recorded sessions
pub struct TuiTestHarness {
    state: Arc<Mutex<TuiState>>,
    backend: ReplayBackend,
    terminal: Terminal<TestBackend>,
}

impl TuiTestHarness {
    pub fn from_fixture(name: &str) -> Self {
        let path = format!("tests/fixtures/{}.jsonl", name);
        let backend = ReplayBackend::from_file(&path).unwrap();
        let terminal = Terminal::new(TestBackend::new(100, 30)).unwrap();
        let state = Arc::new(Mutex::new(TuiState::default()));

        Self { state, backend, terminal }
    }

    pub fn with_terminal_size(mut self, width: u16, height: u16) -> Self {
        self.terminal = Terminal::new(TestBackend::new(width, height)).unwrap();
        self
    }

    /// Process events until iteration N is reached
    pub fn advance_to_iteration(&mut self, n: u32) {
        while let Some(event) = self.backend.next_event() {
            self.state.lock().unwrap().update(&event);
            if self.state.lock().unwrap().iteration >= n {
                break;
            }
        }
    }

    /// Process until specific event topic
    pub fn process_until_event(&mut self, topic: &str) {
        while let Some(event) = self.backend.next_event() {
            let matches = event.topic == topic;
            self.state.lock().unwrap().update(&event);
            if matches {
                break;
            }
        }
    }

    /// Dispatch an action (keyboard input)
    pub fn dispatch_action(&mut self, action: Action) {
        let mut state = self.state.lock().unwrap();
        // Call dispatch_action logic from app.rs
        match action {
            Action::ScrollDown => state.scroll_down(self.viewport_height()),
            Action::ScrollUp => state.scroll_up(),
            Action::NextIteration => state.navigate_next(),
            Action::PrevIteration => state.navigate_prev(),
            // ... other actions
            _ => {}
        }
    }

    /// Initiate search
    pub fn search(&mut self, query: &str) {
        let mut state = self.state.lock().unwrap();
        state.search(query);
    }

    /// Capture current TUI state as snapshot-able struct
    pub fn capture_state(&self) -> TuiSnapshot {
        let state = self.state.lock().unwrap();
        TuiSnapshot {
            iteration: state.iteration,
            current_view: state.current_view,
            total_iterations: state.iterations.len(),
            following_latest: state.following_latest,
            has_alert: state.new_iteration_alert.is_some(),
            search_query: state.search_state.query.clone(),
            search_matches: state.search_state.matches.len(),
            hat_display: state.hat_display(),
            mode: state.mode_display(),
        }
    }

    /// Get current scroll offset
    pub fn current_scroll_offset(&self) -> usize {
        let state = self.state.lock().unwrap();
        state.current_iteration()
            .map(|buf| buf.scroll_offset)
            .unwrap_or(0)
    }

    fn viewport_height(&self) -> u16 {
        self.terminal.size().unwrap().height.saturating_sub(2) // header + footer
    }

    /// Render header widget and return as string
    pub fn render_header(&mut self) -> String {
        // Implementation using TestBackend
        todo!()
    }

    /// Render footer widget and return as string
    pub fn render_footer(&mut self) -> String {
        todo!()
    }

    /// Render full TUI and return as string
    pub fn render_full(&mut self) -> String {
        todo!()
    }
}

#[derive(Debug, serde::Serialize)]
pub struct TuiSnapshot {
    pub iteration: u32,
    pub current_view: usize,
    pub total_iterations: usize,
    pub following_latest: bool,
    pub has_alert: bool,
    pub search_query: Option<String>,
    pub search_matches: usize,
    pub hat_display: String,
    pub mode: String,
}
```

### Snapshot Tests

Create `crates/ralph-tui/tests/integration_snapshots.rs`:

```rust
mod common;
use common::TuiTestHarness;
use insta::{assert_yaml_snapshot, with_settings};
use ralph_tui::Action;

#[test]
fn test_iteration_progression_state() {
    let mut harness = TuiTestHarness::from_fixture("multi_iteration_session");

    // Snapshot state at iteration 1
    harness.advance_to_iteration(1);
    assert_yaml_snapshot!("iter1_state", harness.capture_state());

    // Snapshot state at iteration 2
    harness.advance_to_iteration(2);
    assert_yaml_snapshot!("iter2_state", harness.capture_state());

    // Snapshot state at iteration 3
    harness.advance_to_iteration(3);
    assert_yaml_snapshot!("iter3_state", harness.capture_state());
}

#[test]
fn test_hat_transitions() {
    let mut harness = TuiTestHarness::from_fixture("hat_transitions");

    harness.process_until_event("task.start");
    assert_yaml_snapshot!("hat_after_task_start", harness.capture_state());

    harness.process_until_event("build.task");
    assert_yaml_snapshot!("hat_after_build_task", harness.capture_state());

    harness.process_until_event("build.done");
    assert_yaml_snapshot!("hat_after_build_done", harness.capture_state());
}

#[test]
fn test_navigation_state_preservation() {
    let mut harness = TuiTestHarness::from_fixture("multi_iteration_session");

    // Advance to iteration 3
    harness.advance_to_iteration(3);

    // Navigate back to iteration 1
    harness.dispatch_action(Action::PrevIteration);
    harness.dispatch_action(Action::PrevIteration);
    assert_yaml_snapshot!("nav_back_to_iter1", harness.capture_state());

    // Scroll within iteration 1
    harness.dispatch_action(Action::ScrollDown);
    harness.dispatch_action(Action::ScrollDown);
    let scroll_offset = harness.current_scroll_offset();

    // Navigate to iteration 2 and back
    harness.dispatch_action(Action::NextIteration);
    harness.dispatch_action(Action::PrevIteration);

    // Verify scroll preserved
    assert_eq!(harness.current_scroll_offset(), scroll_offset);
    assert_yaml_snapshot!("scroll_preserved", harness.capture_state());
}

#[test]
fn test_search_state() {
    let mut harness = TuiTestHarness::from_fixture("search_scenario");
    harness.advance_to_iteration(1);

    // Initiate search
    harness.search("error");
    assert_yaml_snapshot!("search_active", harness.capture_state());

    // Navigate matches
    harness.dispatch_action(Action::SearchNext);
    assert_yaml_snapshot!("search_next", harness.capture_state());
}

#[test]
fn test_new_iteration_alert() {
    let mut harness = TuiTestHarness::from_fixture("multi_iteration_session");

    // Advance to iteration 2, then navigate back
    harness.advance_to_iteration(2);
    harness.dispatch_action(Action::PrevIteration);

    // Advance underlying state to iteration 3
    harness.advance_to_iteration(3);

    // Should have alert since viewing old iteration
    let snapshot = harness.capture_state();
    assert!(snapshot.has_alert);
    assert_yaml_snapshot!("new_iteration_alert", snapshot);
}

// Rendered output tests with redactions for dynamic content
#[test]
fn test_header_rendering() {
    let mut harness = TuiTestHarness::from_fixture("multi_iteration_session");
    harness.advance_to_iteration(2);

    with_settings!({
        filters => vec![
            (r"\d{2}:\d{2}", "[TIME]"),  // Redact elapsed time
        ]
    }, {
        assert_snapshot!("header_iter2", harness.render_header());
    });
}

#[test]
fn test_full_layout_responsive() {
    // Test at different terminal widths
    for (width, name) in [(80, "80col"), (60, "60col"), (40, "40col")] {
        let mut harness = TuiTestHarness::from_fixture("multi_iteration_session")
            .with_terminal_size(width, 24);

        harness.advance_to_iteration(1);

        with_settings!({
            filters => vec![
                (r"\d{2}:\d{2}", "[TIME]"),
            ]
        }, {
            assert_snapshot!(format!("full_layout_{}", name), harness.render_full());
        });
    }
}
```

### Recording Fixtures from Real Sessions

```bash
# Record a multi-iteration session
cargo run --bin ralph -- run \
    -c ralph.claude.yml \
    --record-session crates/ralph-tui/tests/fixtures/multi_iteration_session.jsonl \
    -p "Create a file called test.txt, write hello to it, read it back, then delete it. Do each step separately."

# Record hat transition events
cargo run --bin ralph -- run \
    -c ralph.claude.yml \
    --record-session crates/ralph-tui/tests/fixtures/hat_transitions.jsonl \
    -p "Plan a simple task, then implement it"

# Record content with searchable terms
cargo run --bin ralph -- run \
    -c ralph.claude.yml \
    --record-session crates/ralph-tui/tests/fixtures/search_scenario.jsonl \
    -p "Write a function that handles errors gracefully. Include try/catch blocks."

# Record long output for scroll testing
cargo run --bin ralph -- run \
    -c ralph.claude.yml \
    --record-session crates/ralph-tui/tests/fixtures/long_output_scroll.jsonl \
    -p "List all HTTP status codes with descriptions"
```

---

## Tier 2: Real Claude E2E Tests (Behavioral)

### New Test File

Create `tools/e2e/test_tui_behavior.py`:

```python
"""E2E tests for TUI behavior with real Claude invocations.

These tests validate behaviors that require non-deterministic Claude responses:
- Real-time output streaming
- Navigation during active generation
- Search across actual agent output
"""

import asyncio
import re
import pytest

from .helpers import (
    TmuxSession,
    IterationCapture,
    LLMJudge,
)


@pytest.mark.asyncio
@pytest.mark.e2e
@pytest.mark.requires_tmux
@pytest.mark.requires_claude
async def test_tui_shows_output_in_real_time(
    tmux_session: TmuxSession,
    iteration_capture: IterationCapture,
    llm_judge: LLMJudge,
    ralph_binary: Path,
    iteration_config_factory,
):
    """Verify TUI displays Claude output as it streams.

    Given Ralph running with TUI enabled
    When Claude generates multi-line output
    Then TUI content pane shows output incrementally
    And output is formatted with markdown rendering
    """
    config_path = iteration_config_factory(
        max_iterations=5,
        max_runtime_seconds=120,
    )

    cmd = (
        f"{ralph_binary} run "
        f"-c {config_path} "
        f'--tui '
        f'-p "Explain the SOLID principles in software design"'
    )

    await tmux_session.send_keys(cmd)

    # Capture multiple times during generation
    captures = []
    for _ in range(5):
        await asyncio.sleep(2)
        content = await tmux_session.capture_pane()
        captures.append(content)

    # Validate content grows over time (streaming works)
    content_lengths = [len(c) for c in captures]
    assert content_lengths[-1] > content_lengths[0], \
        "Content should grow over time during streaming"

    # LLM-judge validates final output
    result = await llm_judge.validate(
        captures[-1],
        "TUI shows formatted text about software principles. "
        "Header displays iteration count and timing. "
        "Footer shows activity status."
    )
    assert result.passed, f"Validation failed: {result.overall_reason}"


@pytest.mark.asyncio
@pytest.mark.e2e
@pytest.mark.requires_tmux
@pytest.mark.requires_claude
async def test_tui_navigation_during_output(
    tmux_session: TmuxSession,
    iteration_capture: IterationCapture,
    ralph_binary: Path,
    iteration_config_factory,
):
    """Verify navigation works while Claude is generating output.

    Given Ralph running and generating iteration 2 output
    When user navigates to iteration 1 (press 'h')
    Then TUI shows iteration 1 content
    And mode indicator changes to REVIEW
    """
    config_path = iteration_config_factory(
        max_iterations=5,
        max_runtime_seconds=180,
    )

    cmd = (
        f"{ralph_binary} run "
        f"-c {config_path} "
        f'--tui '
        f'-p "First create a simple function, then test it, then document it"'
    )

    await tmux_session.send_keys(cmd)

    # Wait for iteration 2
    capture = await iteration_capture.wait_for_iteration(2, timeout=90)
    assert capture is not None, "Failed to reach iteration 2"

    # Navigate back to iteration 1
    await tmux_session.send_keys('h', enter=False)
    await asyncio.sleep(0.5)

    content = await tmux_session.capture_pane()

    # Should show iteration 1
    assert re.search(r'\[iter\s+1[/\]]', content), \
        f"Should show iteration 1, got: {content[:200]}"

    # Should indicate review mode
    assert 'REVIEW' in content or '[◀' in content, \
        "Should indicate review mode when viewing history"


@pytest.mark.asyncio
@pytest.mark.e2e
@pytest.mark.requires_tmux
@pytest.mark.requires_claude
async def test_tui_search_functionality(
    tmux_session: TmuxSession,
    iteration_capture: IterationCapture,
    llm_judge: LLMJudge,
    ralph_binary: Path,
    iteration_config_factory,
):
    """Verify search works in TUI.

    Given Ralph completed output containing 'error'
    When user searches for 'error' (press '/' then type)
    Then footer shows search query and match count
    And matches are navigable with 'n' and 'N'
    """
    config_path = iteration_config_factory(
        max_iterations=3,
        max_runtime_seconds=90,
    )

    cmd = (
        f"{ralph_binary} run "
        f"-c {config_path} "
        f'--tui '
        f'-p "Explain error handling best practices in Python with examples"'
    )

    await tmux_session.send_keys(cmd)

    # Wait for completion
    exited, _ = await iteration_capture.wait_for_process_exit(timeout=90)
    assert exited, "Process should complete"

    # Initiate search
    await tmux_session.send_keys('/', enter=False)
    await asyncio.sleep(0.2)
    await tmux_session.send_keys('error', enter=False)
    await tmux_session.send_keys('Enter', enter=False)
    await asyncio.sleep(0.3)

    content = await tmux_session.capture_pane()

    # Validate search UI with LLM-judge
    result = await llm_judge.validate(
        content,
        "Footer area shows: "
        "1. The search query 'error' is displayed "
        "2. A match count like '3/10' or 'N matches' is shown "
        "3. Some indication that search is active"
    )
    assert result.passed, f"Search UI validation failed: {result.overall_reason}"

    # Navigate to next match
    await tmux_session.send_keys('n', enter=False)
    await asyncio.sleep(0.2)

    content_after_nav = await tmux_session.capture_pane()

    # Match counter should change or scroll position should change
    assert content_after_nav != content or \
        "2/" in content_after_nav, \
        "Navigation should change view or match counter"


@pytest.mark.asyncio
@pytest.mark.e2e
@pytest.mark.requires_tmux
@pytest.mark.requires_claude
async def test_tui_ctrl_c_termination(
    tmux_session: TmuxSession,
    iteration_capture: IterationCapture,
    ralph_binary: Path,
    iteration_config_factory,
):
    """Verify Ctrl+C cleanly terminates TUI.

    Given Ralph running with TUI
    When user presses Ctrl+C
    Then process terminates cleanly
    And terminal is restored (not in raw mode)
    """
    config_path = iteration_config_factory(
        max_iterations=10,
        max_runtime_seconds=300,
    )

    cmd = (
        f"{ralph_binary} run "
        f"-c {config_path} "
        f'--tui '
        f'-p "Implement a full REST API with authentication"'
    )

    await tmux_session.send_keys(cmd)

    # Wait for TUI to initialize
    await asyncio.sleep(3)

    # Send Ctrl+C
    await tmux_session.send_keys('C-c', enter=False)

    # Wait for termination
    await asyncio.sleep(2)

    content = await tmux_session.capture_pane()

    # Should see shell prompt (terminal restored)
    assert re.search(r'[\$#>]\s*$', content.strip()), \
        "Terminal should be restored with shell prompt visible"


@pytest.mark.asyncio
@pytest.mark.e2e
@pytest.mark.requires_tmux
@pytest.mark.requires_claude
async def test_tui_new_iteration_alert(
    tmux_session: TmuxSession,
    iteration_capture: IterationCapture,
    llm_judge: LLMJudge,
    ralph_binary: Path,
    iteration_config_factory,
):
    """Verify new iteration alert appears when viewing history.

    Given user viewing iteration 1 while iteration 3 is active
    When new iteration starts
    Then footer shows alert about new iteration
    And alert clears when navigating to latest
    """
    config_path = iteration_config_factory(
        max_iterations=5,
        max_runtime_seconds=180,
    )

    cmd = (
        f"{ralph_binary} run "
        f"-c {config_path} "
        f'--tui '
        f'-p "Step 1: Create file. Step 2: Edit file. Step 3: Delete file. Do each in order."'
    )

    await tmux_session.send_keys(cmd)

    # Wait for iteration 2
    await iteration_capture.wait_for_iteration(2, timeout=60)

    # Navigate back to iteration 1
    await tmux_session.send_keys('h', enter=False)
    await asyncio.sleep(0.5)

    # Wait for iteration 3 to start
    await asyncio.sleep(30)  # Give time for next iteration

    content = await tmux_session.capture_pane()

    # Check for new iteration alert in footer
    result = await llm_judge.validate(
        content,
        "Footer shows an alert or notification about a new iteration. "
        "Could be text like 'New: iter 3' or an arrow/indicator pointing right. "
        "Header still shows 'iter 1' (viewing history)."
    )

    # This is a soft assertion - alert behavior may vary
    if not result.passed:
        pytest.skip(f"Alert not detected (may be timing): {result.overall_reason}")
```

---

## Tier 3: Visual Regression with TUI-Validate

Use the existing `/tui-validate` skill for visual regression after TUI changes:

```bash
# Validate header component
/tui-validate file:captured_output.txt criteria:ralph-header

# Validate full layout
/tui-validate tmux:ralph-session criteria:ralph-full save_screenshot:true

# Custom criteria for new features
/tui-validate \
    command:"cargo run --example tui_demo" \
    criteria:"Search UI shows query in footer, highlighted matches in content pane"
```

---

## Test Matrix

| Scenario | Insta Snapshot | Real Claude E2E | TUI-Validate |
|----------|----------------|-----------------|--------------|
| Iteration counter increments | ✅ | ✅ | ✅ |
| Hat transitions | ✅ | ⚪ | ⚪ |
| Scroll state preservation | ✅ | ⚪ | ⚪ |
| Search highlighting | ✅ | ✅ | ✅ |
| Navigation during output | ⚪ | ✅ | ⚪ |
| New iteration alert | ✅ | ✅ | ✅ |
| Terminal cleanup on exit | ⚪ | ✅ | ⚪ |
| Content streaming | ⚪ | ✅ | ⚪ |
| Width-responsive header | ✅ | ⚪ | ✅ |
| Ctrl+C termination | ⚪ | ✅ | ⚪ |

---

## Implementation Phases

### Phase 1: Foundation (Week 1)
- [ ] Add `insta` to ralph-tui dev-dependencies
- [ ] Create `TuiTestHarness` in `tests/common/mod.rs`
- [ ] Record 4 JSONL fixtures from real sessions
- [ ] Implement 5 basic state snapshot tests
- [ ] Run `cargo insta test` and review snapshots

### Phase 2: Coverage (Week 2)
- [ ] Add rendered output snapshot tests with time redactions
- [ ] Implement navigation state preservation tests
- [ ] Add search functionality snapshot tests
- [ ] Create width-responsive tests (80, 60, 40 columns)
- [ ] Total: 15+ snapshot tests

### Phase 3: E2E Enhancement (Week 3)
- [ ] Add `test_tui_behavior.py` with 5 new E2E tests
- [ ] Add `@requires_tui` pytest marker
- [ ] Integrate with CI (separate slow test workflow)
- [ ] Document fixture recording in CONTRIBUTING.md

### Phase 4: CI Integration
- [ ] Add insta snapshot check to pre-commit hook
- [ ] Add snapshot diff check to CI
- [ ] Run E2E tests on merge to main only
- [ ] Set up evidence artifact collection

---

## CI Configuration

Add to `.github/workflows/ci.yml`:

```yaml
jobs:
  tui-unit-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      - name: Run TUI unit tests
        run: cargo test -p ralph-tui

  tui-snapshot-tests:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4

      - name: Install insta CLI
        run: cargo install cargo-insta

      - name: Run snapshot tests
        run: cargo insta test -p ralph-tui

      - name: Check for uncommitted snapshot changes
        run: |
          if [[ -n $(git status --porcelain crates/ralph-tui/tests/snapshots/) ]]; then
            echo "::error::Snapshot changes detected. Run 'cargo insta review' locally."
            git diff crates/ralph-tui/tests/snapshots/
            exit 1
          fi

  tui-e2e-tests:
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main'
    steps:
      - uses: actions/checkout@v4

      - name: Install tmux
        run: sudo apt-get install -y tmux

      - name: Build Ralph
        run: cargo build --release

      - name: Run E2E tests
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        run: |
          pip install pytest pytest-asyncio
          pytest tools/e2e/test_tui_behavior.py -v --tb=short

      - name: Upload evidence artifacts
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: tui-e2e-evidence
          path: tools/e2e/evidence/
```

---

## Running Tests Locally

```bash
# Run all TUI unit tests
cargo test -p ralph-tui

# Run snapshot tests and review changes
cargo insta test -p ralph-tui
cargo insta review

# Run specific snapshot test
cargo test -p ralph-tui integration_snapshots::test_iteration_progression_state

# Record new fixture
cargo run --bin ralph -- run \
    -c ralph.claude.yml \
    --record-session crates/ralph-tui/tests/fixtures/new_fixture.jsonl \
    -p "your prompt here"

# Run E2E tests (requires ANTHROPIC_API_KEY)
cd tools/e2e
pytest test_tui_behavior.py -v

# Run with specific marker
pytest -m "e2e and requires_claude" -v
```

---

## Success Criteria

1. **Snapshot tests pass** with `cargo insta test -p ralph-tui`
2. **No snapshot drift** in CI (all changes reviewed and committed)
3. **E2E tests pass** on main branch merges
4. **Coverage**: All scenarios in test matrix have at least one test type
5. **Documentation**: Fixture recording process documented

---

## References

- [insta documentation](https://insta.rs/)
- [ratatui TestBackend](https://docs.rs/ratatui/latest/ratatui/backend/struct.TestBackend.html)
- Existing tests: `crates/ralph-tui/src/state.rs` (100+ unit tests)
- Existing E2E: `tools/e2e/test_iteration_lifecycle.py`
- TUI validate skill: `.claude/skills/tui-validate/SKILL.md`
